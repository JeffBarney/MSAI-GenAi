{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FurnitureGen: AI-Powered Interior Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeff Barney, MSAI-495: Generative AI Image Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 09:15:10.720054: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 09:15:12.099514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Goal / Case Statement\n",
    "Enable fast, iterative interior design by allowing users to vizualize any room in a different style. \n",
    "\n",
    "### Data\n",
    "* I downloaded my dataset from [Kaggle](https://www.kaggle.com/datasets/stepanyarullin/interior-design-styles) \n",
    "* The dataset consists of a collection of interior design images (~1,000 per style) scraped from Houzz.com\n",
    "* The data set contains 14,876 images in the training set, and 3,729 in the test set\n",
    "* All images are 320x320 and in the jpg file format\n",
    "* Each different style is listed below with an accompanying sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transitional</td>\n",
       "      <td><img src=\"../image-project-data/test/transitional/transitional_354.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>industrial</td>\n",
       "      <td><img src=\"../image-project-data/test/industrial/industrial_846.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shabby-chic-style</td>\n",
       "      <td><img src=\"../image-project-data/test/shabby-chic-style/shabby-chic-style_495.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian</td>\n",
       "      <td><img src=\"../image-project-data/test/asian/asian_638.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>victorian</td>\n",
       "      <td><img src=\"../image-project-data/test/victorian/victorian_880.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coastal</td>\n",
       "      <td><img src=\"../image-project-data/test/coastal/coastal_693.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>southwestern</td>\n",
       "      <td><img src=\"../image-project-data/test/southwestern/southwestern_177.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>craftsman</td>\n",
       "      <td><img src=\"../image-project-data/test/craftsman/craftsman_497.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contemporary</td>\n",
       "      <td><img src=\"../image-project-data/test/contemporary/contemporary_58.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>scandinavian</td>\n",
       "      <td><img src=\"../image-project-data/test/scandinavian/scandinavian_476.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>french-country</td>\n",
       "      <td><img src=\"../image-project-data/test/french-country/french-country_831.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mediterranean</td>\n",
       "      <td><img src=\"../image-project-data/test/mediterranean/mediterranean_87.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rustic</td>\n",
       "      <td><img src=\"../image-project-data/test/rustic/rustic_928.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>farmhouse</td>\n",
       "      <td><img src=\"../image-project-data/test/farmhouse/farmhouse_486.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mid-century-modern</td>\n",
       "      <td><img src=\"../image-project-data/test/mid-century-modern/mid-century-modern_686.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td><img src=\"../image-project-data/test/traditional/traditional_809.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eclectic</td>\n",
       "      <td><img src=\"../image-project-data/test/eclectic/eclectic_142.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tropical</td>\n",
       "      <td><img src=\"../image-project-data/test/tropical/tropical_609.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>modern</td>\n",
       "      <td><img src=\"../image-project-data/test/modern/modern_603.jpg\" width=\"64\"></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import sample_data\n",
    "from IPython.display import HTML\n",
    "\n",
    "df = sample_data()\n",
    "HTML(df.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Load and Normalize the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 11:21:01.083269: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 11:21:02.823615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import fetch_data, preprocess\n",
    "\n",
    "train_data = fetch_data(num_per_label=100)\n",
    "train_data = preprocess(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Build the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Build the Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Combine the Encoder and Decoder into one VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Create an instance of the Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 11:21:52.773953: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 498 of 1000\n",
      "2025-05-01 11:22:02.212816: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "2025-05-01 11:22:21.801263: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from diffusion_model import DiffusionModel\n",
    "from hyperparameters import LOAD_MODEL, WEIGHT_PATH\n",
    "\n",
    "ddm = DiffusionModel()\n",
    "ddm.normalizer.adapt(train_data)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    ddm.built = True\n",
    "    ddm.load_weights(WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step - Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 11:27:13.196344: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:2: Filling up shuffle buffer (this may take a while): 478 of 1000\n",
      "2025-05-01 11:27:24.606446: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m5s\u001b[0m 6s/step - n_loss: 0.3502 "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node mul_1 defined at (most recent call last):\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_3700143/3929987426.py\", line 6, in <module>\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/nee0873/MSAI-GenAi/diffusion_model.py\", line 54, in train_step\n\nIncompatible shapes: [64,1,1,1] vs. [63,64,64,3]\n\t [[{{node mul_1}}]] [Op:__inference_multi_step_on_iterator_40217]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtraining_callbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_checkpoint_callback, tensorboard_callback, image_generator_callback\n\u001b[1;32m      5\u001b[0m ddm\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdamW(learning_rate\u001b[38;5;241m=\u001b[39mLEARNING_RATE, weight_decay\u001b[38;5;241m=\u001b[39mWEIGHT_DECAY), loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanAbsoluteError())\n\u001b[0;32m----> 6\u001b[0m \u001b[43mddm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_generator_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/genai-gpu/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node mul_1 defined at (most recent call last):\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_3700143/3929987426.py\", line 6, in <module>\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/nee0873/.conda/envs/genai-gpu/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/nee0873/MSAI-GenAi/diffusion_model.py\", line 54, in train_step\n\nIncompatible shapes: [64,1,1,1] vs. [63,64,64,3]\n\t [[{{node mul_1}}]] [Op:__inference_multi_step_on_iterator_40217]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import losses, optimizers\n",
    "from hyperparameters import EPOCHS, LEARNING_RATE, WEIGHT_DECAY\n",
    "from training_callbacks import model_checkpoint_callback, tensorboard_callback, image_generator_callback\n",
    "\n",
    "ddm.compile(optimizer=optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY), loss=losses.MeanAbsoluteError())\n",
    "ddm.fit(train_data, epochs=EPOCHS, callbacks=[model_checkpoint_callback(), tensorboard_callback(), image_generator_callback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Visualize the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Test the model for data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some images and pass them through the full flow to visualize the data loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - Calculate vectors for each interior design style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a latent vector for all images in our data set\n",
    "\n",
    "# Compute a latent vector for each style\n",
    "style_vector=mean(latent_vectors_style)−mean(all_latent_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9 - Visualize rooms with a different style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table for each style that shows a before and after of a transformation to some other style\n",
    "new_vector =old_vector + alpha*feature_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
